# CLIP-Sentinel (æ™ºèƒ½è§†è§‰å“¨å…µ)

## ğŸ“– Overview
CLIP-Sentinel is a real-time intelligent visual anomaly detection system. It leverages the semantic power of **CLIP (Contrastive Language-Image Pre-training)** models to detect visual anomalies in video streams. 

Unlike traditional pixel-based motion detection, CLIP-Sentinel uses semantic vectors to understand the content of the scene. It employs a **dual-memory system**:
1.  **Short-term Memory**: Detects sudden changes against the recent context (last minute).
2.  **Long-term Memory**: Validates changes against historical patterns (same time yesterday/last week) to reduce false positives (e.g., scheduled lighting changes).

## ğŸ— System Architecture

```mermaid
graph LR
    A[RTSP Camera] --> B[Stream Sampler]
    B --> C[CLIP Encoder (ViT-B-16-SigLIP2)]
    C --> D[Vector DB (ChromaDB)]
    C --> E[Anomaly Detector]
    D <--> E
    E --> F[WebUI / Alert System]
```

### Key Components
*   **Stream Loader**: Threaded frame capture with latest-frame-only strategy to ensure real-time performance.
*   **Vector Engine**: `open_clip_torch` wrapper utilizing `ViT-B-16-SigLIP2` for high-performance feature extraction.
*   **Memory Store**: `ChromaDB` for persistent vector storage with metadata (timestamp, day, hour).
*   **Detector**: Dual-stage verification logic (Short-term Cosine Similarity + Long-term History Match).
*   **WebUI**: `Streamlit` dashboard with Sci-Fi aesthetics, real-time charts, and visual anomaly history.

## ğŸ” Detection Flow (å½“å‰æ£€æµ‹æµç¨‹)
1. **Frame Sampling**ï¼š`StreamLoader` æŒ‰ `SAMPLE_RATE` è·å–æœ€æ–°å¸§ã€‚
2. **Motion Detection**ï¼š
   - ä½¿ç”¨ MOG2 èƒŒæ™¯å»ºæ¨¡å¾—åˆ°å‰æ™¯æ©ç ã€‚
   - äºŒå€¼åŒ– + å½¢æ€å­¦å¼€è¿ç®—å»å™ªã€‚
   - ç»Ÿè®¡æ‰€æœ‰è½®å»“é¢ç§¯ï¼ˆå•ä¸ªè½®å»“éœ€ â‰¥ `MIN_CONTOUR_AREA`ï¼‰ï¼Œå¹¶è®¡ç®—**æ€»ç§»åŠ¨é¢ç§¯**ã€‚
   - å½“æ€»ç§»åŠ¨é¢ç§¯ â‰¥ `MOTION_THRESHOLD` æ—¶è§¦å‘è¿åŠ¨ï¼Œå¹¶é€‰å–æœ€å¤§è½®å»“ä½œä¸º `motion_box`ã€‚
3. **YOLO Detection**ï¼šè¯†åˆ«æŒ‡å®šç±»åˆ«ç›®æ ‡ï¼Œå¾—åˆ° `yolo_boxes`ã€‚
4. **ROI åˆå¹¶**ï¼šåˆå¹¶ `motion_box` ä¸ `yolo_boxes`ï¼Œè®¡ç®—å¤–æ¥çŸ©å½¢ä½œä¸ºæœ€ç»ˆ ROIï¼Œè¿›è¡Œè£å‰ªã€‚
5. **CLIP ç¼–ç **ï¼šå¯¹ ROI åšå›¾åƒå‘é‡åŒ–ã€‚
6. **Zero-shot åˆ†ç±»**ï¼šåŸºäºæ–‡æœ¬æ ‡ç­¾æ¨æ–­åœºæ™¯è¯­ä¹‰ï¼ˆç”¨äºè§£é‡Š/è¿‡æ»¤ï¼‰ã€‚
7. **å¼‚å¸¸æ£€æµ‹**ï¼šçŸ­æœŸç›¸ä¼¼åº¦ + é•¿æœŸå†å²éªŒè¯ï¼Œè¾“å‡ºå¼‚å¸¸åŸå› ã€‚
8. **æ›´æ–°è®°å¿†**ï¼šå†™å…¥çŸ­æœŸ/é•¿æœŸå‘é‡åº“ï¼Œç”¨äºåç»­å¯¹æ¯”ã€‚

## ğŸ¬ VideoMAE Motion-Only Flow
1. **Frame Sampling**ï¼š`StreamLoader` ä»¥ 1 FPS é‡‡æ ·è¿ç»­å¸§ï¼Œæ„å»º 8 ç§’æ»‘åŠ¨çª—å£ã€‚
2. **Motion Detection**ï¼šåªåšè¿åŠ¨æ£€æµ‹ï¼Œä¸è£å‰ª ROIï¼Œä¹Ÿä¸ä½¿ç”¨ YOLOã€‚
3. **VideoMAE ç¼–ç **ï¼šçª—å£æ»¡ 8 å¸§åï¼Œå¯¹æ•´æ®µè§†é¢‘åš VideoMAE ç¼–ç ã€‚
4. **å¼‚å¸¸æ£€æµ‹**ï¼šçŸ­æœŸ/é•¿æœŸç›¸ä¼¼åº¦å¯¹æ¯”ï¼Œè¾“å‡ºå¼‚å¸¸åŸå› ã€‚
5. **æ›´æ–°è®°å¿†**ï¼šå°† VideoMAE å‘é‡å†™å…¥çŸ­æœŸ/é•¿æœŸå­˜å‚¨ã€‚

## ğŸš€ Getting Started

### Prerequisites
*   Python 3.10+
*   CUDA-enabled GPU (recommended) or CPU (supported)

### Installation

1.  Clone the repository.
2.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```

### Usage

**1. Run the Web Dashboard (Recommended)**
This launches the Sentinel System with a visual interface.
```bash
streamlit run app.py
```
Access the dashboard at `http://localhost:8501`.

**2. Run VideoMAE Motion-Only Dashboard**
This launches the VideoMAE + Motion-only pipeline (no YOLO, no ROI crop).
```bash
streamlit run videomae_app.py
```
Access the dashboard at `http://localhost:8501`.

**3. Run CLI Mode**
If you only need the backend process with logging:
```bash
python main.py
```

## âš™ï¸ Configuration
Edit `config.py` to adjust settings:

*   `RTSP_URL`: URL of the video stream (or path to local video file).
*   `SAMPLE_RATE`: Frames per second to process (default: 1.0).
*   `SIMILARITY_THRESHOLD`: Cosine similarity threshold for anomaly detection (default: 0.85).
*   `HISTORY_WINDOW_SIZE`: Number of frames for short-term moving average.
*   `ANOMALY_METHOD`: `cosine` or `zscore` anomaly scoring method.
*   `ZSCORE_THRESHOLD`: Threshold for z-score based detection (higher = less sensitive).
*   `MOTION_THRESHOLD`: Total moving area threshold (sum of motion contour areas).
*   `MIN_CONTOUR_AREA`: Minimum contour area to be counted as motion.
*   `VIDEOMAE_MODEL_NAME`: VideoMAE model ID used in the motion-only app.
*   `VIDEOMAE_CLIP_SIZE`: Sliding window size (seconds / frames at 1 FPS).
*   `VIDEOMAE_SAMPLE_RATE`: Sampling FPS for the VideoMAE sliding window.
*   `DB_PATH`: Path for ChromaDB persistence.

## ğŸ›  Tech Stack
*   **Language**: Python
*   **Model**: OpenCLIP (ViT-B-16-SigLIP2)
*   **Vision**: OpenCV
*   **Database**: ChromaDB
*   **UI**: Streamlit, Plotly
*   **Utils**: Pydantic, Loguru

## ğŸ“¸ Screenshots
The WebUI provides:
*   Real-time video feed.
*   Status indicators (Normal/Anomaly).
*   Live change-rate chart.
*   History log with snapshots of detected anomalies.
